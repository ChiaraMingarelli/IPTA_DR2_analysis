{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import libstempo as t2\n",
    "from enterprise.signals import utils\n",
    "\n",
    "import dr2lite_utils as dr2u\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DR2dir = os.path.abspath('/Users/ptb/Projects/pulsar/data/DR2')\n",
    "datadir = os.path.join(DR2dir, 'release/VersionA')\n",
    "\n",
    "lite_dir = os.path.join(DR2dir, 'DR2lite_partim')  # cleaned/combined par/tim files\n",
    "os.system('mkdir -p {}'.format(lite_dir));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) clean up `.par` and `.tim` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make list of pulsar names for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psrlist = []\n",
    "psrs = glob.glob(datadir + '/J*')\n",
    "for psr in psrs:\n",
    "    name = psr.split('/')[-1]\n",
    "    psrlist.append(name)\n",
    "psrlist.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean `.par` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parfiles = glob.glob(datadir + '/J*/*IPTADR2.par')\n",
    "\n",
    "for p in parfiles:\n",
    "    name = p.split('/')[-2]\n",
    "    outfile = os.path.join(lite_dir, '{}.par'.format(name))\n",
    "    dr2u.clean_par(p, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine `.tim` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timfiles = glob.glob(datadir + '/J*/*IPTADR2.tim')\n",
    "\n",
    "for t in timfiles:\n",
    "    name = t.split('/')[-2]\n",
    "    outfile = os.path.join(lite_dir, '{}.tim'.format(name))\n",
    "    dr2u.combine_tim(t, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Figure of Merit Calculation\n",
    "\n",
    "Calculate the FoM for each pulsar for each PTA that observes it.\n",
    "\n",
    "From SNR scaling laws...\n",
    "\n",
    "$$ \\mathrm{FoM} = \\frac{T^{13/3}}{\\left<{\\sigma_{TOA}}\\right>^2 \\, \\Delta t} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FoM(Tobs, dt, TOAerr):\n",
    "    \"\"\"GWB FoM from SNR scaling laws\"\"\"\n",
    "    return Tobs**(13/3) / TOAerr**2 / dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter parameters\n",
    "BW = 1.1\n",
    "DM_window = 10\n",
    "\n",
    "Tmin = 5.0  # yrs (of multi-freq coverage)\n",
    "#sigmax = 5.0  # us\n",
    "\n",
    "ptas = ['PPTA', 'EPTA', 'NANOGrav']\n",
    "backends = {'NANOGrav': \n",
    "                ['327_ASP', '430_ASP', 'L-wide_ASP', 'S-wide_ASP',\n",
    "                 '327_PUPPI', '430_PUPPI', 'L-wide_PUPPI',  'S-wide_PUPPI',\n",
    "                 'Rcvr_800_GASP', 'Rcvr1_2_GASP',\n",
    "                 'Rcvr_800_GUPPI', 'Rcvr1_2_GUPPI',\n",
    "                ],\n",
    "            'PPTA': \n",
    "                ['PDFB_10CM', 'PDFB_20CM', 'PDFB_40CM',\n",
    "                 'CPSR2_20CM', 'CPSR2_50CM',\n",
    "                 'WBCORR_10CM', 'WBCORR_20CM',\n",
    "                ],\n",
    "                \n",
    "            'EPTA': \n",
    "                ['EFF.EBPP.1360', 'EFF.EBPP.1410', 'EFF.EBPP.2639',\n",
    "                 'JBO.DFB.1400', 'JBO.DFB.1520',\n",
    "                 'NRT.BON.1400', 'NRT.BON.1600', 'NRT.BON.2000',\n",
    "                 'WSRT.P1.328', 'WSRT.P1.328.C',\n",
    "                 'WSRT.P1.382', 'WSRT.P1.382.C',\n",
    "                 'WSRT.P1.840', 'WSRT.P1.840.C',\n",
    "                 'WSRT.P1.1380', 'WSRT.P1.1380.C',\n",
    "                 'WSRT.P1.1380.1',\n",
    "                 'WSRT.P1.1380.2', 'WSRT.P1.1380.2.C',\n",
    "                 'WSRT.P1.2273.C',\n",
    "                ]\n",
    "           }  # backends to use for each PTA, values for `-group` flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct `FoM_dict` (takes a long time, skip if already saved)\n",
    "\n",
    "Runs `filter_psr()` for each pulsar for each PTA, computing the FoM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redo = True\n",
    "\n",
    "dict_file = 'FoM_gwb_dict.json'  # where to save FoM dictionary\n",
    "data_file = 'FoM_gwb.dat'  # plain text file of FoM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if redo or not os.path.isfile(dict_file):\n",
    "    FoM_dict = {}\n",
    "    fout = open(data_file, 'w')\n",
    "    fout.write('{:11}{:9}{:9}{:9}{:9}{:9}{:12}\\n'\n",
    "               .format('Pulsar', 'PTA', 'raw_Tobs', 'mf_Tobs', 'TOAerr', 'cadence', 'GWB_FoM'))\n",
    "\n",
    "    for psrName in psrlist:\n",
    "        FoM_dict[psrName] = {}\n",
    "    \n",
    "        parfile = os.path.join(lite_dir, '{}.par'.format(psrName))\n",
    "        timfile = os.path.join(lite_dir, '{}.tim'.format(psrName))\n",
    "        psr = t2.tempopulsar(parfile, timfile, maxobs=30000)\n",
    "        for pta in ptas:\n",
    "            if pta in psr.flagvals('pta'):\n",
    "                FoM_dict[psrName][pta] = {}\n",
    "                filt = {'pta':[pta], 'group':backends[pta]}\n",
    "                psr = dr2u.filter_psr(psr, bw=BW, dt=DM_window, filter_dict=filt, plot=False)\n",
    "                \n",
    "                idx = ~psr.deletedmask()\n",
    "                Tobs_raw = (psr.toas().max()-psr.toas().min()) / 365.25\n",
    "                if len(psr.toas()[idx]) > 0:\n",
    "                    U, _ = utils.create_quantization_matrix(psr.toas()[idx]*86400, dt=86400, nmin=1)\n",
    "                    cadence = (psr.toas()[idx].max() - psr.toas()[idx].min()) / U.shape[1] # mean dt\n",
    "                    Tobs = (psr.toas()[idx].max()-psr.toas()[idx].min()) / 365.25\n",
    "                    sigma = 1 / np.mean(1/psr.toaerrs[idx])  # harmonic mean TOAerr\n",
    "                    FoM = compute_FoM(Tobs, cadence, sigma)\n",
    "                else:\n",
    "                    Tobs = 0\n",
    "                    sigma = np.inf\n",
    "                    cadence = np.inf\n",
    "                    FoM = 0\n",
    "                fout.write('{:11}{:9}{:9.2f}{:9.2f}{:9.2f}{:9.2f}{:12.2f}\\n'\n",
    "                            .format(psrName, pta, Tobs_raw, Tobs, sigma, cadence, FoM))\n",
    "                FoM_dict[psrName][pta]['Tobs'] = Tobs\n",
    "                FoM_dict[psrName][pta]['dt'] = cadence\n",
    "                FoM_dict[psrName][pta]['sigma'] = sigma\n",
    "                FoM_dict[psrName][pta]['FoM'] = FoM\n",
    "        del psr\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save `FoM_dict` as `json` database for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if redo or not os.path.isfile(dict_file):\n",
    "\n",
    "    # convert FoM_dict to python float (json can't handle numpy.float128)\n",
    "    for psr in FoM_dict.keys():\n",
    "        for pta in FoM_dict[psr].keys():\n",
    "            for key in FoM_dict[psr][pta].keys():\n",
    "                FoM_dict[psr][pta][key] = float(FoM_dict[psr][pta][key])\n",
    "\n",
    "    with open(dict_file, 'w') as fout:\n",
    "        json.dump(FoM_dict, fout, sort_keys=True, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Select pulsars to use\n",
    "\n",
    "Use only PSRs with `Tmin` yrs of multi-frequency data.  Pick one PTA per pulsar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_file = 'FoM_gwb_dict.json'  # FoM dictionary\n",
    "with open(dict_file, 'r') as fin:\n",
    "    FoM_dict = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psrdict = {}\n",
    "\n",
    "for psrname in psrlist:\n",
    "    best = (None, 0, 0)\n",
    "    for pta in ptas:\n",
    "        try:\n",
    "            this = FoM_dict[psrname][pta]\n",
    "            if this['Tobs'] > Tmin and this['FoM'] > best[-1]:\n",
    "                best = (pta, this['Tobs'], this['FoM'])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if best[0] is not None:\n",
    "        psrdict.update({psrname: {'pta':[best[0]], 'group':backends[best[0]]}})\n",
    "        print('{}: {:8}, T = {:5.2f} yr, FoM = {:6.2f}'.format(psrname, *best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E,N,P = 0,0,0\n",
    "for val in psrdict.values():\n",
    "    val = val['pta']\n",
    "    if 'EPTA' in val:\n",
    "        E += 1\n",
    "    elif 'NANOGrav' in val:\n",
    "        N += 1\n",
    "    elif 'PPTA' in val:\n",
    "        P += 1\n",
    "print(' EPTA - {:2d}\\n   NG - {:2d}\\n PPTA - {:2d}'.format(E,N,P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save `psrdict` to file\n",
    "fname = 'psrdicts/FoM_gwb_psrs.json'\n",
    "with open(fname, 'w') as fout:\n",
    "    json.dump(psrdict, fout, sort_keys=True, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Create filtered par and tim files for DR2-lite GWB analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundir = 'partim_gwb'\n",
    "\n",
    "dr2u.make_dataset(psrdict, indir=lite_dir, outdir=rundir,\n",
    "                  bw=BW, dt=DM_window, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
