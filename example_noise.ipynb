{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Noise\n",
    "\n",
    "Here we demonstrate an example noise analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import glob, json, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from enterprise.pulsar import Pulsar\n",
    "from enterprise.signals import parameter\n",
    "from enterprise.signals import utils\n",
    "from enterprise.signals import signal_base\n",
    "from enterprise.signals import selections\n",
    "from enterprise.signals.selections import Selection\n",
    "from enterprise.signals import white_signals\n",
    "from enterprise.signals import gp_signals\n",
    "from enterprise.signals import deterministic_signals\n",
    "import enterprise.constants as const\n",
    "from enterprise.signals import utils\n",
    "\n",
    "from PTMCMCSampler.PTMCMCSampler import PTSampler as ptmcmc\n",
    "from corner import corner, quantile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change directories and such to match your usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psrName = 'J2317+1439'\n",
    "basedir = os.path.abspath('/Users/ptb/Projects/pulsar/11yr/bwm_results/dr2lite')\n",
    "\n",
    "datadir = os.path.join(basedir, 'partim_bwm')  # par/tim location\n",
    "outdir = os.path.join(basedir, psrName)  # chain file and other output here\n",
    "\n",
    "parfile = os.path.join(datadir, '{}.par'.format(psrName))\n",
    "timfile = os.path.join(datadir, '{}.tim'.format(psrName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in pulsar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psr = Pulsar(parfile, timfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.errorbar(psr.toas/86400, psr.residuals*1e6, psr.toaerrs*1e6, fmt='.')\n",
    "ax.set_xlabel(r\"Time of Arrival (MJD)\")\n",
    "ax.set_ylabel(r\"TOA residual ($\\mu$s)\")\n",
    "ax.set_title(psrName);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since we stripped the **DM variation** model from the `.par` file, you might see some band seperation in the residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup enterprise model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DM model declarations (not in `enterprise` base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential decay for J1713 DM event\n",
    "@signal_base.function\n",
    "def exp_decay(toas, freqs, log10_Amp=-7, t0=54000, log10_tau=1.7):\n",
    "    t0 *= const.day\n",
    "    tau = 10**log10_tau * const.day\n",
    "    wf = - 10**log10_Amp * np.heaviside(toas-t0, 1) * np.exp(-(toas-t0)/tau)\n",
    "    return wf * (1400/freqs)**2\n",
    "\n",
    "# linear interpolation basis in time with nu^-2 scaling (DM variations)\n",
    "@signal_base.function\n",
    "def linear_interp_basis_dm(toas, freqs, dt=30*86400):\n",
    "\n",
    "    # get linear interpolation basis in time\n",
    "    U, avetoas = utils.linear_interp_basis(toas, dt=dt)\n",
    "\n",
    "    # scale with radio frequency\n",
    "    Dm = (1400/freqs)**2\n",
    "\n",
    "    return U * Dm[:, None], avetoas\n",
    "\n",
    "# DMX-like signal with Gaussian prior\n",
    "@signal_base.function\n",
    "def dmx_ridge_prior(avetoas, log10_sigma=-7):\n",
    "    sigma = 10**log10_sigma\n",
    "    return sigma**2 * np.ones_like(avetoas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data selections for white noise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define selection by observing backend\n",
    "bke = selections.Selection(selections.by_backend)\n",
    "\n",
    "# special selection for ECORR (only used for wideband NANOGrav data)\n",
    "bke_NG = selections.Selection(selections.nanograv_backends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white noise parameters\n",
    "#efac = parameter.Uniform(0.5, 10.0)\n",
    "efac = parameter.Normal(1.0, 0.1)\n",
    "equad = parameter.Uniform(-10, -4)\n",
    "ecorr = parameter.Uniform(-10, -4)\n",
    "\n",
    "# red noise and DM parameters\n",
    "log10_A = parameter.Uniform(-20, -11)\n",
    "gamma = parameter.Uniform(0, 7)\n",
    "\n",
    "# DM exponential parameters (for J1713 only)\n",
    "t0 = parameter.Uniform(psr.toas.min()/86400, psr.toas.max()/86400)\n",
    "log10_Amp = parameter.Uniform(-10, -2)\n",
    "log10_tau = parameter.Uniform(np.log10(5), np.log10(500))\n",
    "\n",
    "# DM variations -- DMX-like\n",
    "log10_sigma = parameter.Uniform(-10, -4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white noise signals\n",
    "ef = white_signals.MeasurementNoise(efac=efac, selection=bke)\n",
    "eq = white_signals.EquadNoise(log10_equad=equad, selection=bke)\n",
    "ec = white_signals.EcorrKernelNoise(log10_ecorr=ecorr, selection=bke_NG)\n",
    "\n",
    "# red noise signal\n",
    "pl = utils.powerlaw(log10_A=log10_A, gamma=gamma)\n",
    "rn = gp_signals.FourierBasisGP(pl, components=30)\n",
    "\n",
    "# DMX-like signal\n",
    "dm_window = 10 * const.day\n",
    "dm_basis = linear_interp_basis_dm(dt=dm_window)\n",
    "dm_prior = dmx_ridge_prior(log10_sigma=log10_sigma)\n",
    "dm = gp_signals.BasisGP(dm_prior, dm_basis, name='dm')\n",
    "\n",
    "# DM exponential model (J1713 only)\n",
    "wf = exp_decay(log10_Amp=log10_Amp, t0=t0, log10_tau=log10_tau)\n",
    "dmexp = deterministic_signals.Deterministic(wf, name='exp')\n",
    "\n",
    "# timing model\n",
    "tm = gp_signals.TimingModel(use_svd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full model\n",
    "mod = ef + eq + rn + dm + tm\n",
    "\n",
    "if 'NANOGrav' in psr.flags['pta']:\n",
    "    mod += ec\n",
    "if psr.name == 'J1713+0747':\n",
    "    mod += dmexp\n",
    "\n",
    "# set up PTA of one\n",
    "pta = signal_base.PTA([mod(psr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jump proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JumpProposal(object):\n",
    "\n",
    "    def __init__(self, pta, snames=None):\n",
    "        \"\"\"Set up some custom jump proposals\"\"\"\n",
    "        self.params = pta.params\n",
    "        self.pnames = pta.param_names\n",
    "        self.npar = len(pta.params)\n",
    "        self.ndim = sum(p.size or 1 for p in pta.params)\n",
    "\n",
    "        # parameter map\n",
    "        self.pmap = {}\n",
    "        ct = 0\n",
    "        for p in pta.params:\n",
    "            size = p.size or 1\n",
    "            self.pmap[str(p)] = slice(ct, ct+size)\n",
    "            ct += size\n",
    "\n",
    "        # parameter indices map\n",
    "        self.pimap = {}\n",
    "        for ct, p in enumerate(pta.param_names):\n",
    "            self.pimap[p] = ct\n",
    "\n",
    "        self.snames = {}\n",
    "        for sc in pta._signalcollections:\n",
    "            for signal in sc._signals:\n",
    "                self.snames[signal.signal_name] = signal.params\n",
    "\n",
    "\n",
    "    def draw_from_prior(self, x, iter, beta):\n",
    "        \"\"\"Prior draw.\n",
    "\n",
    "        The function signature is specific to PTMCMCSampler.\n",
    "        \"\"\"\n",
    "\n",
    "        q = x.copy()\n",
    "        lqxy = 0\n",
    "\n",
    "        # randomly choose parameter\n",
    "        idx = np.random.randint(0, self.npar)\n",
    "\n",
    "        # if vector parameter jump in random component\n",
    "        param = self.params[idx]\n",
    "        if param.size:\n",
    "            idx2 = np.random.randint(0, param.size)\n",
    "            q[self.pmap[str(param)]][idx2] = param.sample()[idx2]\n",
    "\n",
    "        # scalar parameter\n",
    "        else:\n",
    "            q[idx] = param.sample()\n",
    "\n",
    "        # forward-backward jump probability\n",
    "        lqxy = param.get_logpdf(x[self.pmap[str(param)]]) - param.get_logpdf(q[self.pmap[str(param)]])\n",
    "\n",
    "        return q, float(lqxy)\n",
    "\n",
    "    def draw_from_red_prior(self, x, iter, beta):\n",
    "\n",
    "        q = x.copy()\n",
    "        lqxy = 0\n",
    "\n",
    "        signal_name = 'red noise'\n",
    "\n",
    "        # draw parameter from signal model\n",
    "        param = np.random.choice(self.snames[signal_name])\n",
    "        if param.size:\n",
    "            idx2 = np.random.randint(0, param.size)\n",
    "            q[self.pmap[str(param)]][idx2] = param.sample()[idx2]\n",
    "\n",
    "        # scalar parameter\n",
    "        else:\n",
    "            q[self.pmap[str(param)]] = param.sample()\n",
    "\n",
    "        # forward-backward jump probability\n",
    "        lqxy = param.get_logpdf(x[self.pmap[str(param)]]) - param.get_logpdf(q[self.pmap[str(param)]])\n",
    "\n",
    "        return q, float(lqxy)\n",
    "\n",
    "    def draw_from_dm_prior(self, x, iter, beta):\n",
    "\n",
    "        q = x.copy()\n",
    "        lqxy = 0\n",
    "\n",
    "        signal_name = 'dm'\n",
    "\n",
    "        # draw parameter from signal model\n",
    "        param = np.random.choice(self.snames[signal_name])\n",
    "        if param.size:\n",
    "            idx2 = np.random.randint(0, param.size)\n",
    "            q[self.pmap[str(param)]][idx2] = param.sample()[idx2]\n",
    "\n",
    "        # scalar parameter\n",
    "        else:\n",
    "            q[self.pmap[str(param)]] = param.sample()\n",
    "\n",
    "        # forward-backward jump probability\n",
    "        lqxy = param.get_logpdf(x[self.pmap[str(param)]]) - param.get_logpdf(q[self.pmap[str(param)]])\n",
    "\n",
    "        return q, float(lqxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sampling groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_parameters(pta):\n",
    "    \"\"\"Utility function for finding global parameters.\"\"\"\n",
    "    pars = []\n",
    "    for sc in pta._signalcollections:\n",
    "        pars.extend(sc.param_names)\n",
    "\n",
    "    gpars = np.unique(list(filter(lambda x: pars.count(x)>1, pars)))\n",
    "    ipars = np.array([p for p in pars if p not in gpars])\n",
    "\n",
    "    return gpars, ipars\n",
    "\n",
    "\n",
    "def get_parameter_groups(pta):\n",
    "    \"\"\"Utility function to get parameter groupings for sampling.\"\"\"\n",
    "    ndim = len(pta.param_names)\n",
    "    groups = [range(0, ndim)]\n",
    "    params = pta.param_names\n",
    "\n",
    "    # get global and individual parameters\n",
    "    gpars, ipars = get_global_parameters(pta)\n",
    "    if any(gpars):\n",
    "        groups.extend([[params.index(gp) for gp in gpars]])\n",
    "\n",
    "    for sc in pta._signalcollections:\n",
    "        for signal in sc._signals:\n",
    "            ind = [params.index(p) for p in signal.param_names if p not in gpars]\n",
    "            if ind:\n",
    "                groups.extend([ind])\n",
    "\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = get_parameter_groups(pta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search dimension\n",
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "ndim = len(x0)\n",
    "\n",
    "# initial jump covariance matrix\n",
    "cov = np.diag(np.ones(ndim) * 0.01**2)\n",
    "\n",
    "sampler = ptmcmc(ndim,\n",
    "                 pta.get_lnlikelihood, pta.get_lnprior,\n",
    "                 cov,\n",
    "                 groups=groups,\n",
    "                 outDir=outdir,\n",
    "                 resume=True,\n",
    "                )\n",
    "\n",
    "outfile = os.path.join(outdir, 'params.txt')\n",
    "with open(outfile, 'w') as f:\n",
    "    for pname in pta.param_names:\n",
    "        f.write(pname+'\\n')\n",
    "\n",
    "print(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp = JumpProposal(pta)\n",
    "sampler.addProposalToCycle(jp.draw_from_prior, 10)\n",
    "sampler.addProposalToCycle(jp.draw_from_red_prior, 10)\n",
    "sampler.addProposalToCycle(jp.draw_from_dm_prior, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {p.name: p.sample() for p in pta.params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pta.get_lnlikelihood(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(5.0e4)\n",
    "\n",
    "sampler.sample(x0, N, SCAMweight=30, AMweight=15, DEweight=50, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing\n",
    "\n",
    "after the chain has gathered sufficient samples you may make some diagnostic plots and save a noisefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_plot(chain, pars, cols=3, wid_per_col=6, aspect_r = 4/3):\n",
    "    rows = len(pars)//cols\n",
    "    if rows*cols < len(pars):\n",
    "        rows += 1\n",
    "\n",
    "    ax = []\n",
    "    width = wid_per_col * cols\n",
    "    height = wid_per_col * rows / aspect_r\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "\n",
    "    for pp, par in enumerate(pars):\n",
    "        ax.append(fig.add_subplot(rows, cols, pp+1))\n",
    "        ax[pp].plot(chain[:,pp]) #, label='')\n",
    "        ax[pp].set_xlabel(par)\n",
    "    return fig\n",
    "\n",
    "def hist_plot(chain, pars, cols=3, bins=30):\n",
    "    rows = len(pars)//cols\n",
    "    if rows*cols < len(pars):\n",
    "        rows += 1\n",
    "\n",
    "    ax = []\n",
    "    fig = plt.figure(figsize=(6*cols, 5*rows))\n",
    "\n",
    "    for pp, par in enumerate(pars):\n",
    "        ax.append(fig.add_subplot(rows, cols, pp+1))\n",
    "        ax[pp].hist(chain[:,pp], bins=bins, normed=True, histtype='step')\n",
    "        ax[pp].set_xlabel(par)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdir, 'params.txt'), 'r') as f:\n",
    "    params = [line.rstrip() for line in f]\n",
    "\n",
    "# WN params\n",
    "par_WN = []\n",
    "idx_WN = []\n",
    "for pp, par in enumerate(params):\n",
    "    if 'efac' in par or 'equad' in par or 'ecorr' in par:\n",
    "        par_WN.append(par)\n",
    "        idx_WN.append(pp)\n",
    "\n",
    "# DM params\n",
    "par_DM = []\n",
    "idx_DM = []\n",
    "for ii, par in enumerate(params):\n",
    "    if '_dm' in par:\n",
    "        par_DM.append(par)\n",
    "        idx_DM.append(ii)\n",
    "\n",
    "# RN params (always last 2)\n",
    "par_RN = params[-2:]\n",
    "idx_RN = []\n",
    "for par in par_RN:\n",
    "    idx_RN.append(params.index(par))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_raw = pd.read_csv(os.path.join(outdir, 'chain_1.txt'),\n",
    "                    sep='\\t', dtype=float, header=None).values\n",
    "len(chain_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnfrac = 0.15\n",
    "thin = 10\n",
    "\n",
    "burn = int(burnfrac * len(chain_raw))\n",
    "\n",
    "ch_WN = chain_raw[burn::thin, idx_WN]\n",
    "ch_RN = chain_raw[burn::thin, idx_RN]\n",
    "ch_DM = chain_raw[burn::thin, idx_DM]\n",
    "ch_like = chain_raw[burn::thin, -4]\n",
    "\n",
    "corL = acor(ch_like)[0]\n",
    "corA = acor(ch_RN[:,1])[0]\n",
    "N = len(ch_like)\n",
    "print(\"N = {}, corL = {}, corA = {}\".format(N, corL, corA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_plot = np.hstack((ch_RN, ch_like.reshape(len(ch_like),1))) # RN and Likelihood chains together\n",
    "par_plot = par_RN + ['log_likelihood']\n",
    "hist_plot(ch_plot, par_plot, cols=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_plot(ch_WN, par_WN, cols=3);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
