{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing IPTA DR2 Data\n",
    "\n",
    "In this notebook we will use `enterprise` to analyze the IPTA DR2 for a stochastic GW background using the NANOGrav 9 year data and the PPTA data that went into DR2 from the PPTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "#%load_ext line_profiler\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as sl\n",
    "\n",
    "import enterprise\n",
    "from enterprise.pulsar import Pulsar\n",
    "import enterprise.signals.parameter as parameter\n",
    "from enterprise.signals import utils\n",
    "from enterprise.signals import signal_base\n",
    "from enterprise.signals import selections\n",
    "from enterprise.signals.selections import Selection\n",
    "from enterprise.signals import white_signals\n",
    "from enterprise.signals import gp_signals\n",
    "from enterprise.signals import deterministic_signals\n",
    "import enterprise.constants as const\n",
    "from enterprise.signals import utils\n",
    "from utils import *\n",
    "\n",
    "\n",
    "import corner\n",
    "from PTMCMCSampler.PTMCMCSampler import PTSampler as ptmcmc\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to convert PAL2 noise parameters to enterprise parameter dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_noise_from_pal2(noisefile):\n",
    "    psrname = noisefile.split('/')[-1].split('_noise.txt')[0]\n",
    "    fin = open(noisefile, 'r')\n",
    "    lines = fin.readlines()\n",
    "    params = {}\n",
    "    for line in lines:\n",
    "        ln = line.split()\n",
    "        if 'efac' in line:\n",
    "            par = 'efac'\n",
    "            flag = ln[0].split('efac-')[-1]\n",
    "        elif 'equad' in line:\n",
    "            par = 'log10_equad'\n",
    "            flag = ln[0].split('equad-')[-1]\n",
    "        elif 'jitter_q' in line:\n",
    "            par = 'log10_ecorr'\n",
    "            flag = ln[0].split('jitter_q-')[-1]\n",
    "        elif 'RN-Amplitude' in line:\n",
    "            par = 'log10_A'\n",
    "            flag = ''\n",
    "        elif 'RN-spectral-index' in line:\n",
    "            par = 'gamma'\n",
    "            flag = ''\n",
    "        else:\n",
    "            break\n",
    "        if flag:\n",
    "            name = [psrname, flag, par]\n",
    "        else:\n",
    "            name = [psrname, par]\n",
    "        pname = '_'.join(name)\n",
    "        params.update({pname: float(ln[1])})\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The pulsars we'll be analyzing\n",
    "psrdict = {'J1713+0747': [{'pta': ['NANOGrav', 'PPTA']}], \n",
    "           'J1909-3744': [{'pta': ['NANOGrav', 'PPTA']}], \n",
    "           'J1640+2224': [{'pta': ['NANOGrav']}], \n",
    "           'J1600-3053': [{'pta': ['NANOGrav']}],\n",
    "           'J2317+1439': [{'pta': ['NANOGrav']}], \n",
    "           'J1918-0642': [{'pta': ['NANOGrav']}], \n",
    "           'J1614-2230': [{'pta': ['NANOGrav']}], \n",
    "           'J1744-1134': [{'pta': ['NANOGrav', 'PPTA']}],\n",
    "           'J0030+0451': [{'pta': ['NANOGrav']}], \n",
    "           'J2145-0750': [{'pta': ['NANOGrav']}], \n",
    "           'J1857+0943': [{'pta': ['NANOGrav']}], \n",
    "           'J1853+1303': [{'pta': ['NANOGrav']}], \n",
    "           'J0613-0200': [{'pta': ['NANOGrav']}],\n",
    "           'J1455-3330': [{'pta': ['NANOGrav']}], \n",
    "           'J1741+1351': [{'pta': ['NANOGrav']}], \n",
    "           'J2010-1323': [{'pta': ['NANOGrav']}], \n",
    "           'J1024-0719': [{'pta': ['NANOGrav']}], \n",
    "           'J1012+5307': [{'pta': ['NANOGrav']}],\n",
    "           'J0437-4715': [{'pta': ['PPTA']}]\n",
    "          }\n",
    "psrlist=psrdict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psrlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get par, tim, and noise files\n",
    "Here we collect the tim and par files as well as noise files made from the `PAL2` code. These are the same par, tim, and noise files used in the 9-year analysis papers. We use the convienience function above to convert from `PAL2` noise files to `enterprise` parameter dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = '../partim_filtered_ppta_ng/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parfiles = sorted(glob.glob(datadir + '/*.par'))\n",
    "timfiles = sorted(glob.glob(datadir + '/*.tim'))\n",
    "\n",
    "# filter\n",
    "parfiles = [x for x in parfiles if x.split('/')[-1].split('.')[0] in psrlist]\n",
    "timfiles = [x for x in timfiles if x.split('/')[-1].split('.')[0] in psrlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(parfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load into Pulsar class list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psrs = []\n",
    "for p, t in zip(parfiles, timfiles):\n",
    "    psr = Pulsar(p, t, ephem='DE436')\n",
    "    psrs.append(psr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get parameter dict from noisefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noisefiles = sorted(glob.glob('../partim_filtered_ppta_ng/noisefiles_ppta_ng_normal/*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "for nf in noisefiles:\n",
    "    with open(nf, 'r') as fin:\n",
    "        params.update(json.load(fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model\n",
    "\n",
    "When setting up the model for our upper limit run we fix all of the white noise (EFAC, EQUAD, and ECORR) parameters to the values obtained from the noise files. This is done by using `Constant` parameters. In this case we do not specify a default value for all instances of that parameter but instead will set them, based on their initialized pulsar and backend specific name, later via the `set_default_params` method of `PTA`. \n",
    "\n",
    "Speaking of white noise parameters here, we also use the `Selection` object.\n",
    "\n",
    "Another feature to notice is that we do not use a uniform prior on the log of the red noise or GWB amplitude. Instead we use a `LinearExp` prior (short for linear-exponent prior), that is a prior of the form $p(x)\\propto 10^x$. This is how we can still use the log of the parameter to sample but place a uniform prior on the parameter itself. We do this for both the red noise and GWB amplitude parameters.\n",
    "\n",
    "Next, in order to save on computing time we do not include spatial correlations here. Instead we model the GWB as a common red process across all pulsars. In `enterprise` we can do this with a simple trick. We pre-initialize the parameters before passing them to the `Signal` model. In this way the *same* parameter instance is used for all pulsars. Lastly, we fixt the spectral index of the GWB to be 13/3 (4.33) using the `Constant` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model\n",
    "\n",
    "We will add some addition model components that are not part of the base enterprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exponential decay function to model \"void\" in J1713+0747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@signal_base.function\n",
    "def exp_decay(toas, freqs, log10_Amp=-7, t0=54000, log10_tau=1.7):\n",
    "    t0 *= const.day\n",
    "    tau = 10**log10_tau * const.day\n",
    "    wf = - 10**log10_Amp * np.heaviside(toas-t0, 1) * np.exp(-(toas-t0)/tau)\n",
    "    return wf * (1400/freqs)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Yearly DM sinusoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@signal_base.function\n",
    "def yearly_sinusoid(toas, freqs, log10_Amp=-7, phase=0):\n",
    "\n",
    "    wf = 10**log10_Amp * np.sin(2*np.pi*const.fyr*toas+phase)\n",
    "    return wf * (1400/freqs)**2\n",
    "\n",
    "@signal_base.function\n",
    "def yearly_sinusoid_basis(toas, freqs):\n",
    "    \n",
    "    F = np.zeros((len(toas), 2))\n",
    "    F[:,0] = np.sin(2*np.pi*toas*const.fyr)\n",
    "    F[:,1] = np.cos(2*np.pi*toas*const.fyr)\n",
    "    \n",
    "    Dm = (1400/freqs)**2\n",
    "\n",
    "    return F * Dm[:, None], np.repeat(const.fyr, 2)\n",
    "\n",
    "@signal_base.function\n",
    "def yearly_sinusoid_prior(f):\n",
    "    return np.ones(len(f)) * 1e20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DM EQUAD (EQUAD) term that scales like $\\nu^{-4}$ (variance remember...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define DM EQUAD variance function\n",
    "@signal_base.function\n",
    "def dmequad_ndiag(freqs, log10_dmequad=-8):\n",
    "    return np.ones_like(freqs) * (1400/freqs)**4 * 10**(2*log10_dmequad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVD timing model basis\n",
    "This allows for more stability over standard scaling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVD timing model basis\n",
    "@signal_base.function\n",
    "def svd_tm_basis(Mmat):\n",
    "    u, s, v = np.linalg.svd(Mmat, full_matrices=False)\n",
    "    return u, np.ones_like(s)\n",
    "\n",
    "@signal_base.function\n",
    "def tm_prior(weights):\n",
    "    return weights * 10**40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the maximum time span to set GW frequency sampling\n",
    "tmin = [p.toas.min() for p in psrs]\n",
    "tmax = [p.toas.max() for p in psrs]\n",
    "Tspan = np.max(tmax) - np.min(tmin)\n",
    "\n",
    "# define selection by observing backend\n",
    "selection = selections.Selection(selections.by_backend)\n",
    "\n",
    "# special selection for ECORR only use wideband NANOGrav data\n",
    "selection2 = selections.Selection(selections.nanograv_backends)\n",
    "\n",
    "# white noise parameters\n",
    "# since we are fixing these to values from the noise file we set\n",
    "# them as constant parameters\n",
    "efac = parameter.Constant()\n",
    "equad = parameter.Constant()\n",
    "ecorr = parameter.Constant()\n",
    "\n",
    "# red noise parameters\n",
    "log10_A = parameter.LinearExp(-20, -11)\n",
    "gamma = parameter.Uniform(0, 7)\n",
    "\n",
    "# GW parameters (initialize with names here to use parameters in common across pulsars)\n",
    "log10_A_gw = parameter.LinearExp(-18,-12)('log10_A_gw')\n",
    "gamma_gw = parameter.Constant(4.33)('gamma_gw')\n",
    "\n",
    "# DM turnover parameters\n",
    "kappa = parameter.Uniform(0,7)\n",
    "lf0 = parameter.Uniform(-9, -6.5)\n",
    "log10_A_DM = parameter.Uniform(-20, -11)\n",
    "\n",
    "# DM exponential parameters\n",
    "t0 = parameter.Uniform(psr.toas.min()/86400, psr.toas.max()/86400)\n",
    "log10_Amp = parameter.Uniform(-10, -2)\n",
    "log10_tau = parameter.Uniform(np.log10(5), np.log10(500))\n",
    "\n",
    "# DM sinusoid parameters\n",
    "log10_Amp_s = parameter.Uniform(-10, -2)\n",
    "phase = parameter.Uniform(0, 2*np.pi)\n",
    "\n",
    "# white noise signals\n",
    "\n",
    "# DM EQUAD\n",
    "#dmvariance = dmequad_ndiag(log10_dmequad=equad)\n",
    "#dmeq = white_signals.WhiteNoise(dmvariance)\n",
    "\n",
    "# white noise\n",
    "ef = white_signals.MeasurementNoise(efac=efac, selection=selection)\n",
    "eq = white_signals.EquadNoise(log10_equad=equad, selection=selection)\n",
    "ec = white_signals.EcorrKernelNoise(log10_ecorr=ecorr, selection=selection2)\n",
    "\n",
    "# red noise (powerlaw with 30 frequencies)\n",
    "pl = utils.powerlaw(log10_A=log10_A, gamma=gamma)\n",
    "rn = gp_signals.FourierBasisGP(spectrum=pl, components=30, Tspan=Tspan)\n",
    "\n",
    "\n",
    "# DM GP signals (use turnover model for more flexibility)\n",
    "dm_basis = utils.createfourierdesignmatrix_dm(nmodes=30)\n",
    "dm_prior = utils.turnover(log10_A=log10_A_DM, gamma=gamma, lf0=lf0, kappa=kappa)\n",
    "dmgp = gp_signals.BasisGP(dm_prior, dm_basis, name='dm')\n",
    "\n",
    "\n",
    "# DM exponential model\n",
    "wf = exp_decay(log10_Amp=log10_Amp, t0=t0, log10_tau=log10_tau)\n",
    "dmexp = deterministic_signals.Deterministic(wf, name='exp')\n",
    "\n",
    "# DM sinusoid model\n",
    "ys_basis = yearly_sinusoid_basis()\n",
    "ys_prior = yearly_sinusoid_prior()\n",
    "dmys = gp_signals.BasisGP(ys_prior, ys_basis, name='s1yr')\n",
    "\n",
    "# gwb (no spatial correlations)\n",
    "cpl = utils.powerlaw(log10_A=log10_A_gw, gamma=gamma_gw)\n",
    "gw = gp_signals.FourierBasisGP(spectrum=cpl, components=30, Tspan=Tspan)\n",
    "\n",
    "# for spatial correltions you can do...\n",
    "#orf = utils.hd_orf()\n",
    "#crn = gp_signals.FourierBasisCommonGP(cpl, orf, components=30, name='gw', Tspan=Tspan)\n",
    "\n",
    "# to add solar system ephemeris modeling...\n",
    "eph = deterministic_signals.PhysicalEphemerisSignal(use_epoch_toas=True)\n",
    "\n",
    "# timing model\n",
    "basis = svd_tm_basis()\n",
    "prior = tm_prior()\n",
    "tm = gp_signals.BasisGP(prior, basis)\n",
    "#tm = gp_signals.TimingModel()\n",
    "\n",
    "# full model\n",
    "#s = ef + eq + rn + dmgp + tm  + dmeq + dmys\n",
    "s = ef + eq + rn + tm + dmgp + dmys + eph + gw #+ dmeq\n",
    "\n",
    "# intialize PTA, adding an exponential dip for the DM event in J1713+0747\n",
    "models = []\n",
    "\n",
    "for p in psrs:    \n",
    "    if 'NANOGrav' in p.flags['pta']:\n",
    "        s2 = s + ec \n",
    "        if p.name == 'J1713+0747':\n",
    "            s3 = s2 + dmexp\n",
    "            models.append(s3(p))\n",
    "        else:\n",
    "            models.append(s2(p))\n",
    "    else:\n",
    "        models.append(s(p))\n",
    "    \n",
    "pta = signal_base.PTA(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set white noise parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pta.set_default_params(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial parameters drawn from prior and evaluate likelihood to fill caches\n",
    "\n",
    "Evaluating the likelihood is not necessary, the caches will be filled the first time it is called within the sampler if not called here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = {par.name: par.sample() for par in pta.params}\n",
    "print pta.get_lnlikelihood(xs);\n",
    "print pta.get_lnprior(xs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "ndim = len(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimension of parameter space\n",
    "#ndim = len(xs)\n",
    "\n",
    "# initial jump covariance matrix\n",
    "cov = np.diag(np.ones(ndim) * 0.01**2)\n",
    "\n",
    "# set up jump groups by red noise groups \n",
    "\n",
    "groups = get_parameter_groups(pta)\n",
    "\n",
    "sampler = ptmcmc(ndim, pta.get_lnlikelihood, pta.get_lnprior, cov, groups=groups, \n",
    "                 outDir='./chains/ipta_dr2_ng_ppta_gwb/',resume=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sampler for N steps\n",
    "N = 1000000\n",
    "x0 = np.hstack(p.sample() for p in pta.params)\n",
    "jp = JumpProposal(pta)\n",
    "sampler.addProposalToCycle(jp.draw_from_prior, 15)\n",
    "sampler.addProposalToCycle(jp.draw_from_ephem_prior, 15)\n",
    "sampler.addProposalToCycle(jp.draw_from_gwb_log_uniform_prior, 10)\n",
    "sampler.sample(x0, N, SCAMweight=30, AMweight=15, DEweight=50, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chain = np.loadtxt('./chains/ipta_dr2_ng_ppta_gwb/chain_1.txt')\n",
    "#pars = sorted(xs.keys())\n",
    "burn = int(0.25 * chain.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(chain[burn:,-5], 50, normed=True, histtype='step', lw=2);\n",
    "#plt.xlabel(pars[-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Upper limit value\n",
    "\n",
    "We see that the upper limit agrees perfectly with the published value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upper = 10**np.percentile(chain[burn:, -5], q=95)\n",
    "print(upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
