{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import libstempo as t2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Clean par and tim files\n",
    "\n",
    "1. Make a directory called `partim` that contains a single par file and single tim file for all pulsars.\n",
    "\n",
    "2. Clean the par files by removing all noise and DM model parameters. We will also add in DM1 and DM2 if not already present in the par file.\n",
    "\n",
    "3. Concatenate all \"INCLUDEs\" into a single tim file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create partim directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DR2DATA = '/home/nanograv/local_data/IPTA_DR2/'\n",
    "datadir = DR2DATA + '/release/VersionA/'\n",
    "parfiles = glob.glob(datadir + '/J*/*IPTADR2.par')\n",
    "os.system('mkdir -p partim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean par files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for parfile in parfiles:\n",
    "    cut = ['T2EFAC', 'T2EQUAD', 'ECORR', 'TNEF', 'TNEQ', 'TNECORR', 'DMMODEL', \n",
    "           '_DM', '_CM', 'CONSTRAIN', 'DMOFF', 'START', 'FINISH', \n",
    "           'TZRSITE'  # maybe remove this\n",
    "          ]\n",
    "    fin = open(parfile, 'r')\n",
    "    lines = fin.readlines()\n",
    "    name = lines[0].split()[1]\n",
    "    fout = open('partim/{}.par'.format(name), 'w')\n",
    "    for line in lines:\n",
    "        if not any([line.startswith(flag) for flag in cut]):\n",
    "            fout.write('%s'%line)\n",
    "            try:\n",
    "                if line.split()[0] == 'DM':\n",
    "                    fout.write('DM1 0 1\\n')\n",
    "                    fout.write('DM2 0 1\\n')\n",
    "            except IndexError:\n",
    "                pass\n",
    "    fin.close()\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine tim files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psrs = glob.glob(datadir + 'J*')\n",
    "for psr in psrs:\n",
    "    name = psr.split('/')[-1]\n",
    "    tfile = open(psr+'/{}.IPTADR2.tim'.format(name), 'r')\n",
    "    lines = tfile.readlines()\n",
    "    timfiles = []\n",
    "    for line in lines:\n",
    "        if not (line.startswith('FORMAT') or line.startswith('#')) and line.strip():\n",
    "            timfiles.append(psr + '/' + line.split()[-1])\n",
    "    tfile.close()\n",
    "    fout = open('partim/{}.tim'.format(name), 'w')\n",
    "    fout.write('FORMAT 1\\n')\n",
    "    fout.write('MODE 1\\n')\n",
    "    for tim in timfiles:\n",
    "        fin = open(tim, 'r')\n",
    "        lines = fin.readlines()\n",
    "        for line in lines:\n",
    "            if not (line.startswith('FORMAT') or line.startswith('MODE') or line.startswith('C')):\n",
    "                fout.write('%s\\n'%line.rstrip())\n",
    "            \n",
    "        fin.close()\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create filtered par and tim files\n",
    "\n",
    "Here we create a filtered dataset by applying a frequency filter and a PTA filter\n",
    "\n",
    "1. **Frequency filter**: Only keep TOAs that have a certain bandwidth (`bw`) coverage over a certain period of time (`dt`). For instance, `dt=7` and `bw=800` will only keep TOAs that have at least 800 MHz of bandwidth (i.e. difference between max and min radio frequency) in every 7 day window.\n",
    "\n",
    "2. **PTA filter**: Only keep TOAs corresponding to a given PTA, or group of PTAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dm_bins(toas, dt=7):\n",
    "    \"\"\"Returns a list of boolean arrays for each time bin corresponding\n",
    "    to TOAs within that bin.\n",
    "    \"\"\"\n",
    "    bins = int(np.ceil((toas.max() - toas.min()) / (86400*dt)))\n",
    "    tmin = toas.min() - 1\n",
    "    tmax = toas.max() + 1\n",
    "    _, xedges = np.histogram(toas, bins=bins, range=[tmin, tmax])\n",
    "    return [np.logical_and(toas >= xedges[ct], toas <= xedges[ct+1]) \n",
    "            for ct in range(len(xedges)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_jumps(psr):\n",
    "    \n",
    "    # Don't use deleted points\n",
    "    mask = psr.deleted[:] == 0\n",
    "        \n",
    "    # find JUMP parameter indices\n",
    "    idx = np.array([1+ct for ct, p in enumerate(psr.pars()) if 'JUMP' in p])\n",
    "\n",
    "    # get list of TOAs in each jump\n",
    "    M = psr.designmatrix()[mask, :]\n",
    "    jbool = [(M[:, ix]!=0.0).astype(int) for ix in idx]\n",
    "\n",
    "    # check if all TOAs are juped\n",
    "    if np.sum(np.sum(jbool, axis=0) != 0) >= len(psr.toas()[mask]):\n",
    "        print('All TOAs are being jumped!')\n",
    "\n",
    "        # find JUMP group with lowest weighted variance\n",
    "        maxind = np.argmax([(1/psr.toaerrs[mask][np.flatnonzero(M[:, ix])]**2).sum() for ix in idx])\n",
    "        jpar = psr.pars()[idx[maxind]-1]\n",
    "        print('Setting {} as reference jump.\\n'.format(jpar))\n",
    "        psr[jpar].fit = False\n",
    "        psr[jpar].val = 0\n",
    "\n",
    "        # run libstempo fitter to refit jumps relative to new reference\n",
    "        _ = psr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_psr(psr, bw=1.1, dt=7, filters=None, frequency_filter=True, \n",
    "               fmax=3000, verbose=True, plot=True):\n",
    "    \"\"\"Returns a new `libstempo` object that has the frequency and optional PTA filter applied.\"\"\"\n",
    "    \n",
    "    psr.deleted[:] = 1\n",
    "    print('Working on PSR {}'.format(psr.name))\n",
    "    \n",
    "    # Flag filtering\n",
    "    idx0 = []\n",
    "    or_filters = []\n",
    "    if filters:\n",
    "        for fltr in filters:\n",
    "            for key, val in fltr.items():\n",
    "                if verbose: print('Keeping TOAs corresponding to {} {}'.format(key, val))\n",
    "                flag_conds = [(psr.flagvals(key)==v).astype(int) for v in val]\n",
    "                or_filters.append((np.sum(flag_conds, axis=0) != 0).astype(int))\n",
    "    \n",
    "    idx0 = np.flatnonzero(np.prod(or_filters, axis=0).astype(bool))\n",
    "    \n",
    "    # filter for frequency coverage\n",
    "    if frequency_filter:\n",
    "        bins = get_dm_bins(psr.toas()*86400, dt=dt)\n",
    "        idx = []\n",
    "        for bn in bins:\n",
    "            if sum(bn) > 1:\n",
    "                ix = filter(lambda x: x in idx0, np.flatnonzero(bn))\n",
    "                if len(ix) > 0:\n",
    "                    if psr.freqs[ix].max() / psr.freqs[ix].min() >= bw:\n",
    "                        idx.append(ix)\n",
    "                    elif psr.freqs[ix].max() >= fmax:\n",
    "                        idx.append(ix)\n",
    "                        \n",
    "            \n",
    "        # check for empty list (i.e. there is no multi-frequency data)\n",
    "        if not idx:\n",
    "            print \"No multi-frequency data, returning original psr\"\n",
    "            return psr\n",
    "\n",
    "        # delete\n",
    "        idx = np.unique(np.concatenate(idx))\n",
    "    else:\n",
    "        idx = idx0\n",
    "    psr.deleted[idx] = 0\n",
    "                \n",
    "    # filter design matrix\n",
    "    mask = psr.deleted[:] == 0\n",
    "    M = psr.designmatrix()[mask, :]\n",
    "    dpars = []\n",
    "    for ct, (par, val) in enumerate(zip(psr.pars(), M.sum(axis=0)[1:])):\n",
    "        if val == 0:\n",
    "            dpars.append(par)\n",
    "            psr[par].fit = False\n",
    "            psr[par].val = 0.0\n",
    "    if verbose:\n",
    "        print('Cutting {} TOAs'.format(np.sum(~mask)))\n",
    "        print('Turning off fit for {}'.format(dpars))\n",
    "        print('\\n')\n",
    "    fix_jumps(psr)\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8,3))\n",
    "        for pta in np.unique(psr.flagvals('pta')):\n",
    "            nix = psr.flagvals('pta') == pta\n",
    "            plt.plot(psr.toas()[nix], psr.freqs[nix], '.', label=pta)\n",
    "        plt.plot(psr.toas()[~psr.deletedmask()], psr.freqs[~psr.deletedmask()], '.', \n",
    "                 color='C3', alpha=0.3, label='filtered')\n",
    "        plt.legend(loc='best', frameon=False)\n",
    "        plt.title(psr.name)\n",
    "    return psr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(psrdict, outdir='partim_filtered', frequency_filter=True, \n",
    "                 fmax=3000, plot=True, verbose=True):\n",
    "    \"\"\"Makes a filtered dataset\"\"\"\n",
    "    \n",
    "    os.system('rm -rf {}'.format(outdir))\n",
    "    os.system('mkdir -p {}'.format(outdir))\n",
    "    for pname, filters in sorted(psrdict.items()):\n",
    "        parfile = 'partim/{}.par'.format(pname)\n",
    "        timfile = 'partim/{}.tim'.format(pname)\n",
    "        psr = t2.tempopulsar(parfile, timfile, maxobs=30000)\n",
    "        if isinstance(frequency_filter, dict):\n",
    "            ff = frequency_filter[pname]\n",
    "        else:\n",
    "            ff = frequency_filter\n",
    "        psr = filter_psr(psr, bw=1.1, dt=30, filters=filters, frequency_filter=ff, \n",
    "                         fmax=fmax, plot=plot, verbose=verbose)\n",
    "        psr.savetim('{}/{}.tim'.format(outdir, pname))\n",
    "        psr.savepar('{}/{}.par'.format(outdir, pname))\n",
    "        del psr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dataset_old(psrdict, outdir='partim_filtered'):\n",
    "    \"\"\"Makes a filtered dataset\"\"\"\n",
    "    \n",
    "    os.system('rm -rf {}'.format(outdir))\n",
    "    os.system('mkdir -p {}'.format(outdir))\n",
    "    for pname, filters in sorted(psrdict.items()):\n",
    "        parfile = 'partim/{}.par'.format(pname)\n",
    "        timfile = 'partim/{}.tim'.format(pname)\n",
    "        psr = t2.tempopulsar(parfile, timfile, maxobs=30000)\n",
    "        if pname in ['J0437-4715', 'J2317+1439']:\n",
    "            frequency_filter = False\n",
    "        else:\n",
    "            frequency_filter = True\n",
    "        try:\n",
    "            psr = filter_psr(psr, bw=1.1, dt=30, filters=filters, frequency_filter=frequency_filter)\n",
    "            psr.savetim('{}/{}.tim'.format(outdir, pname))\n",
    "            psr.savepar('{}/{}.par'.format(outdir, pname))\n",
    "            del psr\n",
    "        except:\n",
    "            print(\"no data, skipping\")\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulsar dictionary\n",
    "\n",
    "This is input to the `make_dataset` function. We list the pulsars we want to include along with the corresponding PTAs we want to use. In the case below we only have one PTA per pulsar but one could use `['NANOGrav', 'PPTA']` as well as any other combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example PTA dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NG9 + 0437\n",
    "psrdict = {'J1713+0747': [{'pta': ['NANOGrav']}, \n",
    "                          {'f': ['Rcvr1_2_GASP', 'Rcvr1_2_GUPPI', \n",
    "                                 'Rcvr_800_GASP', 'Rcvr_800_GUPPI', \n",
    "                                 'L-wide_ASP', 'L-wide_PUPPI','S-wide_ASP', \n",
    "                                 'S-wide_PUPPI']}], \n",
    "           'J1909-3744': [{'pta': ['NANOGrav']}], \n",
    "           'J1640+2224': [{'pta': ['NANOGrav']}], \n",
    "           'J1600-3053': [{'pta': ['NANOGrav']}],\n",
    "           'J2317+1439': [{'pta': ['NANOGrav']}], \n",
    "           'J1918-0642': [{'pta': ['NANOGrav']}], \n",
    "           'J1614-2230': [{'pta': ['NANOGrav']}], \n",
    "           'J1744-1134': [{'pta': ['NANOGrav']}],\n",
    "           'J0030+0451': [{'pta': ['NANOGrav']}], \n",
    "           'J2145-0750': [{'pta': ['NANOGrav']}], \n",
    "           'J1857+0943': [{'pta': ['NANOGrav']}], \n",
    "           'J1853+1303': [{'pta': ['NANOGrav']}], \n",
    "           'J0613-0200': [{'pta': ['NANOGrav']}],\n",
    "           'J1455-3330': [{'pta': ['NANOGrav']}], \n",
    "           'J1741+1351': [{'pta': ['NANOGrav']}], \n",
    "           'J2010-1323': [{'pta': ['NANOGrav']}], \n",
    "           'J1024-0719': [{'pta': ['NANOGrav']}], \n",
    "           'J1012+5307': [{'pta': ['NANOGrav']}],\n",
    "           'J0437-4715': [{'pta': ['PPTA']}]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NG9 + PPTA4\n",
    "psrdict = {'J1713+0747': [{'pta': ['NANOGrav', 'PPTA']}, \n",
    "                          {'f': ['Rcvr1_2_GASP', 'Rcvr1_2_GUPPI', \n",
    "                                 'Rcvr_800_GASP', 'Rcvr_800_GUPPI', \n",
    "                                 'L-wide_ASP', 'L-wide_PUPPI','S-wide_ASP', \n",
    "                                 'S-wide_PUPPI', '1050CM_CPSR2', '1050CM_PDFB1', \n",
    "                                 '1050CM_PDFB2', '1050CM_PDFB3',\n",
    "                                 '1050CM_PDFB4', '1050CM_WBCORR', 'H-OH_CPSR2m', 'H-OH_CPSR2n',\n",
    "                                 'H-OH_PDFB1', 'MULTI_CPSR2m', 'MULTI_CPSR2n', 'MULTI_PDFB1',\n",
    "                                 'MULTI_PDFB2', 'MULTI_PDFB3', 'MULTI_PDFB4', 'MULTI_WBCORR']}], \n",
    "           'J1909-3744': [{'pta': ['NANOGrav', 'PPTA']}], \n",
    "           'J1640+2224': [{'pta': ['NANOGrav']}], \n",
    "           'J1600-3053': [{'pta': ['NANOGrav']}],\n",
    "           'J2317+1439': [{'pta': ['NANOGrav']}], \n",
    "           'J1918-0642': [{'pta': ['NANOGrav']}], \n",
    "           'J1614-2230': [{'pta': ['NANOGrav']}], \n",
    "           'J1744-1134': [{'pta': ['NANOGrav', 'PPTA']}],\n",
    "           'J0030+0451': [{'pta': ['NANOGrav']}], \n",
    "           'J2145-0750': [{'pta': ['NANOGrav']}], \n",
    "           'J1857+0943': [{'pta': ['NANOGrav']}], \n",
    "           'J1853+1303': [{'pta': ['NANOGrav']}], \n",
    "           'J0613-0200': [{'pta': ['NANOGrav']}],\n",
    "           'J1455-3330': [{'pta': ['NANOGrav']}], \n",
    "           'J1741+1351': [{'pta': ['NANOGrav']}], \n",
    "           'J2010-1323': [{'pta': ['NANOGrav']}], \n",
    "           'J1024-0719': [{'pta': ['NANOGrav']}], \n",
    "           'J1012+5307': [{'pta': ['NANOGrav']}],\n",
    "           'J0437-4715': [{'pta': ['PPTA']}]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NG9 with 1713, 1744, 1909, 0437 from PPTA\n",
    "psrdict = {'J1713+0747': [{'pta': ['PPTA']}], \n",
    "           'J1909-3744': [{'pta': ['PPTA']}], \n",
    "           'J1640+2224': [{'pta': ['NANOGrav']}], \n",
    "           'J1600-3053': [{'pta': ['NANOGrav']}],\n",
    "           'J2317+1439': [{'pta': ['NANOGrav']}], \n",
    "           'J1918-0642': [{'pta': ['NANOGrav']}], \n",
    "           'J1614-2230': [{'pta': ['NANOGrav']}], \n",
    "           'J1744-1134': [{'pta': ['PPTA']}],\n",
    "           'J0030+0451': [{'pta': ['NANOGrav']}], \n",
    "           'J2145-0750': [{'pta': ['NANOGrav']}], \n",
    "           'J1857+0943': [{'pta': ['NANOGrav']}], \n",
    "           'J1853+1303': [{'pta': ['NANOGrav']}], \n",
    "           'J0613-0200': [{'pta': ['NANOGrav']}],\n",
    "           'J1455-3330': [{'pta': ['NANOGrav']}], \n",
    "           'J1741+1351': [{'pta': ['NANOGrav']}], \n",
    "           'J2010-1323': [{'pta': ['NANOGrav']}], \n",
    "           'J1024-0719': [{'pta': ['NANOGrav']}], \n",
    "           'J1012+5307': [{'pta': ['NANOGrav']}],\n",
    "           'J0437-4715': [{'pta': ['PPTA']}]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shannon Science paper data\n",
    "psrdict = {'J1713+0747': [{'pta': ['PPTA']}, {'group': ['PDFB_10CM', 'WBCORR_10CM']}], \n",
    "           'J1909-3744': [{'pta': ['PPTA']}, {'group': ['PDFB_10CM', 'WBCORR_10CM']}], \n",
    "           'J1744-1134': [{'pta': ['PPTA']}, {'group': ['PDFB_10CM', 'WBCORR_10CM']}],\n",
    "           'J0437-4715': [{'pta': ['PPTA']}, {'group': ['PDFB_10CM', 'WBCORR_10CM']}]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psrdict = {}\n",
    "PSRnames = glob.glob('partim/*.par')\n",
    "\n",
    "for psrname in PSRnames:\n",
    "    name = psrname.split('/')[-1].split('.')[0]\n",
    "    psrdict.update({name: [{'pta':['EPTA']}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_dataset(psrdict, outdir='partim_epta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
